{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = ['8clusters4x2.txt','4clusts.txt','4clusts_proximity.txt','6clusters3x2.txt','10d-4c-no0.dat','10d-4c-no1.dat',\n",
    "#         '10d-4c-no2.dat','10d-4c-no3.dat','10d-4c-no4.dat','10d-4c-no5.dat','10d-4c-no6.dat','10d-4c-no7.dat','10d-4c-no8.dat',\n",
    "#         '10d-4c-no9.dat','10d-10c-no0.dat','10d-10c-no1.dat','10d-10c-no2.dat','10d-10c-no3.dat','10d-10c-no4.dat','10d-10c-no5.dat',\n",
    "#         '10d-10c-no6.dat','10d-10c-no7.dat','10d-10c-no8.dat','10d-10c-no9.dat','10d-20c-no0.dat','10d-20c-no1.dat','10d-20c-no2.dat',\n",
    "#         '10d-20c-no3.dat','10d-20c-no4.dat','10d-20c-no5.dat','10d-20c-no6.dat','10d-20c-no7.dat','10d-20c-no8.dat','10d-20c-no9.dat',\n",
    "#         '10d-40c-no0.dat','10d-40c-no1.dat','10d-40c-no2.dat','10d-40c-no3.dat','10d-40c-no4.dat','10d-40c-no5.dat','10d-40c-no6.dat',\n",
    "#         '10d-40c-no7.dat','10d-40c-no8.dat','10d-40c-no9.dat', '15clusters5x3.txt', 'aggregation_edit.txt','banana_edit.txt','banknote.txt',\n",
    "#         'brain_cancer.txt','breast-cancer-wisconsin.txt','ckplus_norm.txt','colon_cancer.txt','compound_edit.txt','D31_edit.txt','diffDensities_edit.txt',\n",
    "#         'ecoli_v2.txt','examples1_edit.txt','flame_edit.txt','football_data.txt','gesture_phase_segmentation_a1_all.txt',\n",
    "#         'grid5_edit.txt','human_activity_recognition_all.txt','iris_edit.txt','jaffe_norm.txt','jain_edit.txt','lotsOfClusters5_edit.txt',\n",
    "#         'lung_cancer.txt','lymphoma_cancer.txt','movement_libras.data','pathbased_edit.txt','prostate_cancer.txt','R15.txt','sat.trn',\n",
    "#         'seeds.txt','segment.dat','spambase.txt','spiral.txt','spiralsquare.txt','srbct_cancer.txt','s-set2.txt','wine.txt','yeast.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = ['data_d20_c_10_no_0.txt','data_d20_c_10_no_1.txt','data_d20_c_10_no_2.txt','data_d20_c_10_no_3.txt','data_d20_c_10_no_4.txt',\n",
    "#        'data_d20_c_20_no_0.txt','data_d20_c_20_no_1.txt','data_d20_c_20_no_2.txt','data_d20_c_20_no_3.txt','data_d20_c_20_no_4.txt',\n",
    "#        'data_d20_c_35_no_0.txt','data_d20_c_35_no_1.txt','data_d20_c_35_no_2.txt','data_d20_c_35_no_3.txt','data_d20_c_35_no_4.txt',\n",
    "#        'data_d20_c_50_no_0.txt','data_d20_c_50_no_1.txt','data_d20_c_50_no_2.txt','data_d20_c_50_no_3.txt','data_d20_c_50_no_4.txt',\n",
    "#        'data_d35_c_10_no_0.txt','data_d35_c_10_no_1.txt','data_d35_c_10_no_2.txt','data_d35_c_10_no_3.txt','data_d35_c_10_no_4.txt',\n",
    "#        'data_d35_c_20_no_0.txt','data_d35_c_20_no_1.txt','data_d35_c_20_no_2.txt','data_d35_c_20_no_3.txt','data_d35_c_20_no_4.txt',\n",
    "#        'data_d35_c_35_no_0.txt','data_d35_c_35_no_1.txt','data_d35_c_35_no_2.txt','data_d35_c_35_no_3.txt','data_d35_c_35_no_4.txt',\n",
    "#        'data_d35_c_50_no_0.txt','data_d35_c_50_no_1.txt','data_d35_c_50_no_2.txt','data_d35_c_50_no_3.txt','data_d35_c_50_no_4.txt',\n",
    "#        'data_d50_c_10_no_0.txt','data_d50_c_10_no_1.txt','data_d50_c_10_no_2.txt','data_d50_c_10_no_3.txt','data_d50_c_10_no_4.txt',\n",
    "#        'data_d50_c_20_no_0.txt','data_d50_c_20_no_1.txt','data_d50_c_20_no_2.txt','data_d50_c_20_no_3.txt','data_d50_c_20_no_4.txt',\n",
    "#        'data_d50_c_35_no_0.txt','data_d50_c_35_no_1.txt','data_d50_c_35_no_2.txt','data_d50_c_35_no_3.txt','data_d50_c_35_no_4.txt',\n",
    "#        'data_d50_c_50_no_0.txt','data_d50_c_50_no_1.txt','data_d50_c_50_no_2.txt','data_d50_c_50_no_3.txt','data_d50_c_50_no_4.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\ISI\\Datasets\\datasets\n"
     ]
    }
   ],
   "source": [
    "cd E:/ISI/Datasets/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "\n",
    "def ret_cs(data,k,algo):\n",
    "    cs_list = np.zeros((k, data.shape[1]))\n",
    "    \n",
    "    # Randomly initialise first center\n",
    "    cs_list[0] = data[np.random.randint(1, data.shape[0])]\n",
    "    \n",
    "    #define some heuristic for m\n",
    "    m = 5/(math.sqrt(data.shape[1])*math.log10(k+30))\n",
    "    distance = np.zeros((k, data.shape[0]))\n",
    "    mean = np.zeros(k)\n",
    "    j = 0\n",
    "    while j < k-1:\n",
    "        distance[j,:] = np.linalg.norm((data - cs_list[j]), axis = 1)\n",
    "        mean[j] = distance[j,:].mean()\n",
    "        \n",
    "        dist_set = distance[0:j+1] > (mean[0:j+1][:,None] * m)\n",
    "        sdn = np.sum(dist_set, axis=0) == (j+1)\n",
    "        if sdn.sum() > 0:\n",
    "            index_set = np.where(sdn)[0]\n",
    "            dist_mean = np.mean(distance[j,index_set])\n",
    "\n",
    "            if algo == 'mean':\n",
    "                closest_value = min(distance[j, index_set], key=lambda x:abs(x-dist_mean))\n",
    "                index = index_set[np.where(distance[j, index_set] == closest_value)[0][0]]\n",
    "                cs_list[j+1] = data[index]\n",
    "            elif algo == 'max':\n",
    "                index = index_set[np.where(distance[j, index_set] == np.max(distance[j, index_set]))[0][0]]\n",
    "                cs_list[j+1] = data[index]\n",
    "            elif algo == 'min':\n",
    "                index = index_set[np.where(distance[j, index_set] == np.min(distance[j, index_set]))[0][0]]\n",
    "                cs_list[j+1] = data[index]\n",
    "            j = j + 1\n",
    "        else:\n",
    "            m = m - 0.025\n",
    "        #print(m)\n",
    "    return cs_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: 8clusters4x2.txt\n",
      "k: 8\n",
      "[5.1        0.9689457  5.3        0.96905191 5.3        0.96916702]\n",
      "\n",
      "DATASET: 4clusts.txt\n",
      "k: 4\n",
      "[2. 1. 2. 1. 2. 1.]\n",
      "\n",
      "DATASET: 4clusts_proximity.txt\n",
      "k: 4\n",
      "[5.         0.93453919 4.63333333 0.93453919 4.26666667 0.93453919]\n",
      "\n",
      "DATASET: 6clusters3x2.txt\n",
      "k: 6\n",
      "[5.53333333 0.97215315 5.73333333 0.97215315 5.         0.97215315]\n",
      "\n",
      "DATASET: 10d-4c-no0.dat\n",
      "k: 4\n",
      "[9.33333333 0.84237474 6.8        0.92876361 9.63333333 0.82858021]\n",
      "\n",
      "DATASET: 10d-4c-no1.dat\n",
      "k: 4\n",
      "[4.56666667 0.96186385 5.23333333 0.97677033 8.33333333 0.97677033]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = ['8clusters4x2.txt','4clusts.txt','4clusts_proximity.txt','6clusters3x2.txt','10d-4c-no0.dat','10d-4c-no1.dat']\n",
    "matrix = np.zeros((30,6))\n",
    "matrix_mean_30runs = np.zeros((len(file),6))\n",
    "no_of_runs = 30\n",
    "for i in range(len(file)):\n",
    "    dataset = str(file[i])\n",
    "    print('DATASET:',dataset)\n",
    "    a = np.loadtxt(file[i])\n",
    "    k = len(np.unique(a[:,a.shape[1]-1]))\n",
    "    print('k:',k)\n",
    "    b = a[:,:a.shape[1]-1]\n",
    "    for j in range(no_of_runs):\n",
    "        cs_mean = ret_cs(b,k,'mean')\n",
    "        cs_max = ret_cs(b,k,'max')\n",
    "        #print(cs_mean)\n",
    "        kmeans = KMeans(n_clusters=k, init = cs_mean, max_iter=100, n_init=1).fit(b)\n",
    "        iterations = kmeans.n_iter_\n",
    "        matrix[j,0] = iterations\n",
    "        matrix[j,1] = ARI(kmeans.labels_, a[:,a.shape[1]-1])\n",
    "        kmeans = KMeans(n_clusters=k, init = cs_max, max_iter=100, n_init=1).fit(b)\n",
    "        iterations = kmeans.n_iter_\n",
    "        matrix[j,2] = iterations\n",
    "        matrix[j,3] = ARI(kmeans.labels_, a[:,a.shape[1]-1])\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=100, n_init=1).fit(b)\n",
    "        iterations = kmeans.n_iter_\n",
    "        matrix[j,4] = iterations\n",
    "        matrix[j,5] = ARI(kmeans.labels_, a[:,a.shape[1]-1])\n",
    "    #print(matrix)\n",
    "    matrix_mean_30runs[i] = np.mean(matrix,axis=0)\n",
    "    print(matrix_mean_30runs[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"results.csv\", matrix_mean_30runs, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
